---
title: "[음원 데이터를 활용한 주간음원순위 예측](https://github.com/YooGunWook/1nurse4stat)"
subtitle: "[2020-01 데이터사이언스입문 프로젝트](https://statkclee.github.io/ds-intro-2020/)"
author: 
    name: "사응일간 ([강동원](https://github.com/dw3624), [백원희](https://github.com/Wonhee-baek), [오태환](https://github.com/dhxoghks95), [유건욱](https://github.com/YooGunWook), [이청파](https://github.com/leechungpa))"
date: '최종수정일 : `r Sys.Date()`'
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: hide
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




# Preprocessing & EDA

## 파생변수 생성

### title_song 생성

- Idea : 높은 인기로 인해 음원차트에 2곡 이상의 곡을 진입시킨 가수들이 있다. 타이틀곡이 아닌 곡의 경우에는 가수의 다른 지표가 좋아도 타이틀곡에 비해 순위가 낮을 수 밖에 없다. 따라서 그 주차에 한 가수가 진입시킨 곡들 중에 가장 순위가 높은 곡을 title_song이라고 정하고 title_song인 경우는 TRUE, 아닌 경우는 FALSE를 할당하는 변수를 만들었다.

- Example : 

|artist|name|week|rank_g|
|---|--|---|---|
|청하|벌써 12시|2019-01-02|1|
|청하|나의 의미|2019-01-02|5|
|청하|Roller Coster|2019-01-02|6|

* 한 주차에 같은 가수의 곡이 세 개 있다. 이런 경우 가장 높은 순위인 **벌써 12시**에 TRUE를 할당하고 나머지엔 FALSE를 할당한다. 

|artist|name|week|rank_g|title_song|
|---|--|---|---|---|
|청하|벌써 12시|2019-01-02|1|TRUE|
|청하|나의 의미|2019-01-02|5|FALSE|
|청하|Roller Coster|2019-01-02|6|FALSE|


### previous_ranking 생성

- Idea : 당연히 음원차트 순위 예측은 이전 순위에 영향을 받을 것이다. 따라서 기존에 차트에 있는 곡은 이전주차 순위를, 신곡의 경우는 그 가수가 직전에 낸 음반의 title_song의 rank_g중 가장 높은(1에 가까운) 순위를 할당하였다. rank의 영향력을 줄이기 위해 rank를 그대로 활용하는 것 보단, 1~200까지의 rank를 1, 10, 20, 30 과 같이 20개의 그룹으로 만들어서 넣었다.

- Example : 

|artist|name|week|rank_g|
|---|--|---|---|
|청하|벌써 12시|2019-01-02|1|
|청하|벌써 12시|2019-01-09|21|
|청하|벌써 12시|2019-01-16|42|
|청하|Snapping|2019-10-13|1|
|청하|Snapping|2019-10-20|22|
|청하|Snapping|2019-10-27|32|

* 맨 위 행의 경우는 이전 곡에 대한 정보가 없다. 따라서 previous_ranking에 NA가 할당된다. 
* 두 번째 행의 경우는 이전 주차의 순위가 1위이므로 previous_ranking에 1이 할당된다.
* 네 번째 행의 경우는 신곡이므로 이전 곡의 top ranking인 1이 할당된다.
* 다섯 번째 행의 경우는 이전 주차의 순위인 1위가 할당된다.

할당 결과는 다음과 같다

|artist|name|week|rank_g|previous_ranking|
|---|--|---|---|---|
|청하|벌써 12시|2019-01-02|1|NA|
|청하|벌써 12시|2019-01-09|2|1|
|청하|벌써 12시|2019-01-16|4|2|
|청하|Snapping|2019-10-13|1|1|
|청하|Snapping|2019-10-20|2|1|
|청하|Snapping|2019-10-27|3|2|

### top_freq 생성

- Idea : 음원 중엔 소위 "연금"이라고 불리는 곡들이 있다. 장기간 차트에 진입했다는 것을 의미한다. 우리는 그러한 오랜 기간 사랑받은 곡을 판별하기 위해 이러한 변수를 만들었다. 

- Example : 


|artist|name|week|rank_g|
|---|--|---|---|
|청하|벌써 12시|2019-01-02|1|
|청하|벌써 12시|2019-01-09|2|
|청하|벌써 12시|2019-01-16|4|
|청하|벌써 12시|2019-01-23|4|
|오마이걸|불꽃놀이|2019-10-13|3|
|오마이걸|불꽃놀이|2019-11-20|4|
|오마이걸|불꽃놀이|2019-12-20|4|
|트와이스|Signal|2019-11-27|3|
|트와이스|Signal|2019-12-27|3|
|블랙핑크|불장난|2019-12-27|4|

* 이제 각 곡이 차트인 한 횟수를 세어 칼럼을 만들자

|artist|name|week|rank_g|top_freq|
|---|--|---|---|---|
|청하|벌써 12시|2019-01-02|1|4|
|청하|벌써 12시|2019-01-09|2|4|
|청하|벌써 12시|2019-01-16|4|4|
|청하|벌써 12시|2019-01-23|4|4|
|오마이걸|불꽃놀이|2019-10-13|3|3|
|오마이걸|불꽃놀이|2019-11-20|4|3|
|오마이걸|불꽃놀이|2019-12-20|4|3|
|트와이스|Signal|2019-10-27|3|2|
|트와이스|Signal|2019-11-27|3|2|
|블랙핑크|불장난|2019-12-27|4|1|

### season_genre_score 생성

- Idea : 가을 겨울엔 발라드, 여름엔 댄스. 보통 사람들의 인식 속에 계절별로 인기있는 장르가 다르다. 실제로도 그런 경향이 있는지 확인하고 싶었다.

- Process

먼저 실제로 계절간 장르 인기의 변동이 있는지 확인해보자.

```{r , message=F,warning=F}
sge = readr::read_csv('https://raw.githubusercontent.com/YooGunWook/1nurse4stat/master/data/model_data/eda_data_season_genre.csv')

plotly::plot_ly(sge, x = ~season, y = ~ seasonal_mean, color = ~genre, type = "scatter",mode = 'markers+lines') 
```

계절별 변동이 확실하게 보인다

- season_genre_score 만들기
```{r}
knitr::kable(sge)
```

이런 식으로 장르별 계절별 평균 rank_g를 구한 뒤


$$
(\frac{mean\ seasonal\ rank\ by\ genre - genre\ mean\ rank }{genre\ mean\ rank}) 
$$


이 계산을 통해 장르 평균 순위에 비해 계절별 평균 순위가 얼마나 다른지를 파생변수로 만든다.

## Transformation for skewed data

왜도가 커보이는 데이터들을 찾아 log transformation으로 최대한 정규분포로 맞춰주자

```{r, include = FALSE}
library(tidyverse)
data = read_csv("https://raw.githubusercontent.com/YooGunWook/1nurse4stat/master/data/model_data/NA_%EC%A0%9C%EA%B1%B0.csv")
summary(data)
data = data[,-1]
```

### nv_score

```{r, message=FALSE}
data%>% select(nv_score) %>% ggplot(aes(x = nv_score)) + geom_density()+ ggtitle("Before Transformation")
```

데이터가 왼쪽에 쏠려있다.

```{r, warning=FALSE}
data %>% select(nv_score) %>% transmute(nv_score = log(nv_score)) %>%ggplot(aes(x = nv_score + 1)) + geom_density()+ ggtitle("After Transformation")
```
로그변환을 하니 정규분포에 더 가까워졌다.

같은 방식으로 다른 왜도가 보이는 데이터들도 변환해주자.

### total_view

```{r}
data%>% select(total_view) %>% ggplot(aes(x = total_view)) + geom_density()+ ggtitle("Before Transformation")
```

```{r, warning=FALSE}
data %>% select(total_view) %>% transmute(total_view = log(total_view)) %>%ggplot(aes(x = total_view)) + geom_density() + ggtitle("After Transformation")
```


### pd_score
```{r}
data%>% select(pd_score) %>% ggplot(aes(x = pd_score)) + geom_density()+ ggtitle("Before Transformation")
```
```{r, warning=FALSE}
data %>% select(pd_score) %>% transmute(pd_score = log(pd_score)) %>%ggplot(aes(x = pd_score)) + geom_density()+ ggtitle("After Transformation")
```



### dc_total_numb
```{r}
data%>% select(dc_total_numb) %>% ggplot(aes(x = dc_total_numb)) + geom_density()+ ggtitle("Before Transformation")
```

```{r, warning=FALSE}
data %>% select(dc_total_numb) %>% transmute(dc_total_numb = log(dc_total_numb)) %>%ggplot(aes(x = dc_total_numb)) + geom_density()+ ggtitle("After Transformation")
```


### dc_mean_reccomend

```{r}
data%>% select(dc_mean_reccomend) %>% ggplot(aes(x = dc_mean_reccomend)) + geom_density()+ggtitle("Before Transformation")
```
```{r, warning=FALSE}
data %>% select(dc_mean_reccomend) %>% transmute(dc_mean_reccomend = log(dc_mean_reccomend)) %>%ggplot(aes(x = dc_mean_reccomend)) + geom_density()+ ggtitle("After Transformation")
```

### dc_mean_views

```{r}
data%>% select(dc_mean_views) %>% ggplot(aes(x = dc_mean_views)) + geom_density()+ ggtitle("Before Transformation")
```

```{r, warning=FALSE}
data %>% select(dc_mean_views) %>% transmute(dc_mean_views = log(dc_mean_views)) %>%ggplot(aes(x = dc_mean_views)) + geom_density()+ ggtitle("After Transformation")
```


### drama_view

```{r}
data%>% select(drama_view) %>% ggplot(aes(x = drama_view)) + geom_density()+ ggtitle("Before Transformation")
```
```{r, warning=FALSE}
data %>% select(drama_view) %>% transmute(drama_view = log(drama_view)) %>%ggplot(aes(x = drama_view)) + geom_density()+ ggtitle("After Transformation")
```


## Scaling

$$
(\frac{x - min(x)}{max(x) - min(x)})
$$

이 식을 사용해 최소 0, 최대 1로 min-max scaling을 진행했다.




