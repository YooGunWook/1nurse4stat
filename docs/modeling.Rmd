---
title: "[음원 데이터를 활용한 주간음원순위 예측](https://github.com/YooGunWook/1nurse4stat)"
subtitle: "[2020-01 데이터사이언스입문 프로젝트](https://statkclee.github.io/ds-intro-2020/)"
author: 
    name: "사응일간 ([강동원](https://github.com/dw3624), [백원희](https://github.com/Wonhee-baek), [오태환](https://github.com/dhxoghks95), [유건욱](https://github.com/YooGunWook), [이청파](https://github.com/leechungpa))"
date: '최종수정일 : `r Sys.Date()`'
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: hide
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Modeling

## 사용한 모델

- Linear Regression
- Random Forest
- Catboost
- XGboost

```{r ,eval = FALSE}
library(reticulate)
use_condaenv("anaconda3")
```

이번 프로젝트에서는 1~200위까지 순위를 예측했다. 사용된 test 데이터는 2020년 4월 19일이고, 그 외 데이터들이 train과 validation set이다.

원래 순위 예측과는 다르게 Classification이 아닌 Regression으로 순위를 예측하려고 한다. Regression을 통해 실제 순위와 얼마나 차이 나는지 파악했다. Classification의 경우 정확하게 예측하지 않는 이상 예측 평가에서 매우 떨어지기 때문에 실제값과 예측값간의 차이를 나타낼 수 있는 Regression으로 예측하기로 했다. 

<br>
각 모델별로 Cross Validation을 통해 모델의 유효성을 검증했다. 모델의 성능 평가는 RMSE를 사용했다.
$$
RMSE = \sqrt{\frac{1}{n}\Sigma(\hat{y}_i - y_i)^2}
$$

## Modeling Process

### Classification

처음에는 순위를 10위 단위로 묶어서 Classification을 진행했다. 
그러나 분석을 진행하면서 범주로 10위 단위로 묶었을 때 성능은 좋더라도 정확한 예측이라고는 판단하기 힘들었다. 
특히 이전 순위를 그대로 따라가는 경향을 보였다. 
왜냐하면 11위와 19위는 똑같은 범주 안에 묶여있고 주 단위로는 크게 변하지 않기 때문이다. 이러한 결과는 본 조에서 원하는 결과는 아니었다.
따라서 본 조는 Classification이 아닌 Regression을 통해서 1~200위를 예측하는 것이 타당하다고 생각했다. 

### Regression

Regression을 통해서 보려는 것은 다음과 같다. 

- 예측과 실제 값 간의 차이가 얼마나 나오는지 확인한다.
- 10위 단위가 아닌 실제 순위와 얼마나 가깝게 예측하는 지 확인한다. 


## Modeling Result

### Linear Regression 

- Linear Regression은 일반 선형회귀로, y값이 연속형일 때 사용한다. 
- 모델의 해석에 큰 장점을 가지고 있다. 
- 이 프로젝트에서는 해석보다는 예측에 초점을 맞췄기 때문에 Python Sklearn 패키지에 있는 LinearRegression을 사용했다. 

```{python, eval=FALSE}
from sklearn.linear_model import LinearRegression
LR_model = LinearRegression()
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = -1 * cross_val_score(LR_model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
LR_model.fit(X_train,y_train)
pred_y = LR_model.predict(X_test)
```

모델의 성능은 다음과 같이 나왔다. 

- Valid set: 21.009
- Test set: 21.325

### Random Forest

- Random Forest는 Tree 기반의 모형으로, Decision Tree의 단점을 보완한 앙상블 모델이다. 
- Random Forest는 Python Sklearn에 있는 RandomForestRegressor를 사용했다. 

```{python, eval=FALSE}
f_model = RandomForestRegressor(random_state =1, n_estimators = 500)
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = -1 * cross_val_score(f_model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
f_model(X_train,y_train)
pred_y = f_model.predict(X_test)
```
변수 중요도는 다음과 같은 순서로 나왔다. 

- previous_ranking
- top_freq
- gg_score
- nv_score
- runtime

모델 성능은 다음과 같이 나왔다. 

- Valid Set: 18.771
- Test Set: 21.330


### Catboost

- Catboost는 오류에 가중치를 주는 Boosting 기반의 모델이고, Boosting 모델 중에서 범주형 변수에 특화되어 있다. 
- 모델에 사용된 데이터에 총 7의 범주형 데이터를 가지고 있기 때문에 이 모델을 사용하는 것이 적합하다고 판단했다.
- Python의 catboost 패키지를 사용했다. 

```{python, eval=FALSE}
from catboost import CatBoostRegressor
cat_model = CatBoostRegressor(n_estimators= 5000, learning_rate = 0.001, border_count = 7, depth = 10, random_state= 1,cat_features = cat)
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = cross_val_score(model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
cat_model.fit(X_train,y_train)
pred_y = cat_model.predict(X_test)
```
변수 중요도는 다음과 같은 순서로 나왔다. 

- previous_ranking	
- top_freq
- you_rank_g
- title_song
- song_type
- season

모델 성능은 다음과 같이 나왔다. 

- Valid Set: 20.827
- Test Set: 22.286


### XGboost

- XGboost는 오류에 가중치를 주는 Boosting 기반의 모델이고, Gradient Boosting의 단점을 보완한 모델이다. 
- 파라미터를 어떻게 조정하냐에 따라 예측력이 많이 변하는 특징을 가지고 있다. 
- Python의 xgboost 패키지를 사용했다. 

```{python, eval = FALSE}
from xgboost import XGBRegressor
xg_model = XGBRegressor(n_estimators = 2000,learning_rate = 0.05, random_state = 1)
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = cross_val_score(model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
xg_model.fit(X_train, y_train)
pred_y = xg_model.predict(X_test)
```
변수 중요도는 다음과 같은 순서로 나왔다. 

- top_freq	
- nv_score
- runtime
- gg_score
- pd_score
- total_view

다른 모델과는 다르게 previous ranking이 순위 안에 없는 것을 확인할 수 있다. 다른 모델에 비해 이전 순위가 아닌 다른 변수들로 순위를 예측한 것이다. 

모델 성능은 다음과 같이 나왔다. 

- Valid Set: 18.640
- Test Set: 21.16875

<br>
최종적으로 다음과 같이 결과가 나왔다.

|Model|Valid|Test|
|---|--|---|
|LinearRegression|21.009|21.325|
|RandomForest|18.771|21.330|
|CatBoost|20.827|22.286|
|XGBoost|18.640|21.16875|



# Result

- 모델링 과정 중 이전 순위가 결측치인 경우 10으로 채워서 진행했지만 문제가 있었다. 
  - 이 변수의 영향을 너무 크게 받아서 이전 순위를 그대로 따라가는 경향을 보였다.
  - 신곡인 경우 그 전 노래의 영향은 생각보다 크지 않고, 가수의 인지도가 큰 영향을 끼칠거라고 생각했다. 
  - 이전 순위의 경우 NA를 채우지 않고 그대로 진행했다.
  - NA를 그대로 두고 진행했을 때 더 좋은 결과가 나왔다.
  
- 모델별 변수 중요도가 다르게 나온것을 확인할 수 있다.
- 대부분의 모델에서는 Previous ranking이 가장 중요하게 나왔지만, XGboost에서는 나름 중요한 변수이긴 했으나 상위 6개 중에서는 나오지 않았다. 
- 모델의 성능 평가를 보면 XGboost가 다른 모델에 비해 높은 성능을 보여주고 있다. 
- 최종적으로 RMSE가 가장 낮은 XGBoost를 선정했다. 
  
  
