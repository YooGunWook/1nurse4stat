---
title: "[음원 데이터를 활용한 주간음원순위 예측](https://github.com/YooGunWook/1nurse4stat)"
subtitle: "[2020-01 데이터사이언스입문 프로젝트](https://statkclee.github.io/ds-intro-2020/)"
author: 
    name: "사응일간 ([강동원](https://github.com/dw3624), [백원희](https://github.com/Wonhee-baek), [오태환](https://github.com/dhxoghks95), [유건욱](https://github.com/YooGunWook), [이청파](https://github.com/leechungpa))"
date: '최종수정일 : `r Sys.Date()`'
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: hide
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Modeling

## 사용한 모델

- Linear Regression
- Random Forest
- Catboost
- XGboost

```{r ,eval = FALSE}
library(reticulate)
use_condaenv("anaconda3")
```

이번 프로젝트에서는 1~200위까지 순위를 예측했다. 사용된 test 데이터는 2020년 4월 19일이고, 그 외 데이터들이 train과 validation set이다.

원래 순위 예측과는 다르게 Classification이 아닌 Regression으로 순위를 예측하려고 한다. Regression을 통해 실제 순위와 얼마나 차이 나는지 파악했다. 
<br>
각 모델별로 Cross Validation을 통해 모델의 유효성을 검증했다. 모델의 성능 평가는 MSE를 사용했다.
$$
RMSE = \sqrt{\frac{1}{n}\Sigma(\hat{y}_i - y_i)^2}
$$

### Linear Regression 

- Linear Regression은 일반 선형회귀로, y값이 연속형일 때 사용한다. 
- 이 프로젝트에서는 해석보다는 예측에 초점을 맞췄기 때문에 Python Sklearn 패키지에 있는 LinearRegression을 사용했다. 

```{python, eval=FALSE}
from sklearn.linear_model import LinearRegression
LR_model = LinearRegression()
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = -1 * cross_val_score(LR_model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
LR_model.fit(X_train,y_train)
pred_y = LR_model.predict(X_test)
```
- Valid set: 21.009
- Test set: 21.325


### Random Forest

- Random Forest는 Tree 기반의 모형으로, Decision Tree의 단점을 보완한 앙상블 모델이다. 
- Random Forest는 Python Sklearn에 있는 RandomForestRegressor를 사용했다. 

```{python, eval=FALSE}
f_model = RandomForestRegressor(random_state =1, n_estimators = 500)
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = -1 * cross_val_score(f_model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
f_model(X_train,y_train)
pred_y = f_model.predict(X_test)
```
- Valid Set: 18.771
- Test Set: 21.330


### Catboost

- Catboost는 오류에 가중치를 주는 Boosting 기반의 모델이고, Boosting 모델 중에서 범주형 변수에 특화되어 있다. 
- 모델에 사용된 데이터에 총 7의 범주형 데이터를 가지고 있기 때문에 이 모델을 사용하는 것이 적합하다고 판단했다.
- Python의 catboost 패키지를 사용했다. 

```{python, eval=FALSE}
from catboost import CatBoostRegressor
cat_model = CatBoostRegressor(n_estimators= 5000, learning_rate = 0.001, border_count = 7, depth = 10, random_state= 1,cat_features = cat)
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = cross_val_score(model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
cat_model.fit(X_train,y_train)
pred_y = cat_model.predict(X_test)
```
- Valid Set: 20.827
- Test Set: 22.286


### XGboost

- XGboost는 오류에 가중치를 주는 Boosting 기반의 모델이고, Gradient Boosting의 단점을 보완한 모델이다. 
- 파라미터를 어떻게 조정하냐에 따라 예측력이 많이 변하는 특징을 가지고 있다. 
- Python의 xgboost 패키지를 사용했다. 

```{python, eval = FALSE}
from xgboost import XGBRegressor
xg_model = XGBRegressor(n_estimators = 2000,learning_rate = 0.05, random_state = 1)
stf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)
score = cross_val_score(model, X_train, y_train, cv = stf, scoring = 'neg_mean_squared_error')
xg_model.fit(X_train, y_train)
pred_y = xg_model.predict(X_test)
```
- Valid Set: 18.640
- Test Set: 21.16875


## 모델링 과정 

- 각 모델별로 하이퍼 파라미터를 따로 조정하지 않고 모델을 훈련 시켰다. 
- 그중에서 모델 성능이 가장 높은 모델을 선택해서 grid search 진행했다. 
- 최종적으로 RMSE가 가장 낮은 XGBoost를 선정했다. 
  - 선정 근거
    - 다른 모델들에 비해 Cross_validation 성능이 안정적이다. 
    - 많은 데이터들이 들어왔을 때 최대한 정확하게 맞추는 모델이 더 중요하다.
    
- 모델링 과정 중 이전 순위가 결측치인 경우 10으로 채워서 진행했는데, 이부분에서 문제가 발생했다. 
  - 이 변수의 영향을 너무 크게 받아서 이전 순위를 그대로 따라가는 경향을 보였다.
  - 이전 순위의 경우 NA를 채우지 않고 그대로 진행했다.
  - NA를 그대로 두고 진행했을 때 더 좋은 결과가 나왔다. 
  
  
  





